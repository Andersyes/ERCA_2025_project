{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b23564-450b-43b6-bd49-210d1303a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Download Copernicus data =================\n",
    "'''\n",
    "The documentation can be found here: https://cds.climate.copernicus.eu/how-to-api\n",
    "The standard code looks like this:\n",
    "import cdsapi    \n",
    "client = cdsapi.Client()\n",
    "dataset = \"<DATASET-SHORT-NAME>\"\n",
    "request = {\n",
    "    <SELECTION-REQUEST>\n",
    "}\n",
    "target = \"<TARGET-FILE>\"\n",
    "client.retrieve(dataset, request, target)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0055e790-74c1-4954-9be5-de81e8f9b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 08:07:23,065 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2025-01-21 08:07:23,067 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-01-21 08:07:23,068 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2025-01-21 08:07:23,069 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-01-21 08:07:24,259 INFO [2025-01-09T00:00:00] Please be aware that ERA5 data from 1st January 2025 was degraded and is being corrected. Watch the [Forum announcement](https://forum.ecmwf.int/t/era5-data-from-1st-january-2025-was-degraded-and-is-being-corrected/10689) for updates.\n",
      "2025-01-21 08:07:24,261 INFO Request ID is 39656284-a0d1-4f22-810c-54994571febf\n",
      "2025-01-21 08:07:24,336 INFO status has been updated to accepted\n",
      "2025-01-21 08:07:45,783 INFO status has been updated to running\n",
      "2025-01-21 08:08:14,420 INFO Daily reduction: mean {'time_shift': {'hours': -1}, 'remove_partial_periods': True}\n",
      "2025-01-21 08:08:40,117 INFO Daily reduction: mean {'time_shift': {'hours': 0}, 'remove_partial_periods': True}\n",
      "2025-01-21 08:09:18,629 INFO Daily reduction: mean {'time_shift': {'hours': 0}, 'remove_partial_periods': True}\n",
      "2025-01-21 08:09:18,631 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ca35b274c54285a0062763ce47c3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "d55f6b000b655eb28587b6f991d078da.zip:   0%|          | 0.00/66.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './prepared-data/anderson_test/ERA5/cloudIce_201808.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./prepared-data/anderson_test/ERA5/cloudIce_201808.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m client \u001b[38;5;241m=\u001b[39m cdsapi\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/datapi/legacy_api_client.py:179\u001b[0m, in \u001b[0;36mLegacyApiClient.retrieve\u001b[0;34m(self, name, request, target)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     submitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    175\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[1;32m    177\u001b[0m     )\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m submitted \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msubmitted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/datapi/processing.py:659\u001b[0m, in \u001b[0;36mResults.download\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    656\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(target)\n\u001b[1;32m    658\u001b[0m robust_download \u001b[38;5;241m=\u001b[39m multiurl\u001b[38;5;241m.\u001b[39mrobust(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_options)\n\u001b[0;32m--> 659\u001b[0m \u001b[43mrobust_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_size(target)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/multiurl/http.py:479\u001b[0m, in \u001b[0;36mrobust.<locals>.wrapped\u001b[0;34m(url, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call(main_url, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/datapi/processing.py:625\u001b[0m, in \u001b[0;36mResults._download\u001b[0;34m(self, url, target)\u001b[0m\n\u001b[1;32m    623\u001b[0m download_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume_transfers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    624\u001b[0m download_options\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_options)\n\u001b[0;32m--> 625\u001b[0m \u001b[43mmultiurl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/multiurl/downloader.py:111\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, target, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload\u001b[39m(url, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.12/site-packages/multiurl/base.py:128\u001b[0m, in \u001b[0;36mDownloaderBase.download\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    121\u001b[0m size, mode, skip, trust_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_size(download)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar(\n\u001b[1;32m    124\u001b[0m     total\u001b[38;5;241m=\u001b[39msize,\n\u001b[1;32m    125\u001b[0m     initial\u001b[38;5;241m=\u001b[39mskip,\n\u001b[1;32m    126\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle(),\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    129\u001b[0m         total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransfer(f, pbar)\n\u001b[1;32m    131\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './prepared-data/anderson_test/ERA5/cloudIce_201808.zip'"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "dataset = \"derived-era5-single-levels-daily-statistics\"\n",
    "request = {\n",
    "    \"product_type\": \"reanalysis\",\n",
    "    \"variable\": [\n",
    "        \"surface_thermal_radiation_downwards\",\n",
    "        \"cloud_base_height\",\n",
    "        \"total_column_cloud_ice_water\"\n",
    "    ],\n",
    "    \"year\": \"2018\",\n",
    "    \"month\": [\n",
    "        \"08\"\n",
    "    ],\n",
    "    \"day\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\",\n",
    "        \"13\", \"14\", \"15\",\n",
    "        \"16\", \"17\", \"18\",\n",
    "        \"19\", \"20\", \"21\",\n",
    "        \"22\", \"23\", \"24\",\n",
    "        \"25\", \"26\", \"27\",\n",
    "        \"28\", \"29\", \"30\",\n",
    "        \"31\"\n",
    "    ],\n",
    "    \"daily_statistic\": \"daily_mean\",\n",
    "    \"time_zone\": \"utc+00:00\",\n",
    "    \"frequency\": \"6_hourly\",\n",
    "    \"area\": [90, -180, 30, 180]\n",
    "}\n",
    "target = './prepared-data/anderson_test/ERA5/cloudIce_201808.zip'\n",
    "client = cdsapi.Client()\n",
    "client.retrieve(dataset, request, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6194ea74-1970-4d33-a344-ae2901825728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 21:36:53,685 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2025-01-20 21:36:53,688 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-01-20 21:36:53,689 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2025-01-20 21:36:53,690 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2025-01-20 21:36:54,042 INFO [2025-01-09T00:00:00] Please be aware that ERA5 data from 1st January 2025 was degraded and is being corrected. Watch the [Forum announcement](https://forum.ecmwf.int/t/era5-data-from-1st-january-2025-was-degraded-and-is-being-corrected/10689) for updates.\n",
      "2025-01-20 21:36:54,043 INFO Request ID is 2f8dc260-3943-44ea-ba87-c0daff91711d\n",
      "2025-01-20 21:36:54,099 INFO status has been updated to accepted\n",
      "2025-01-20 21:37:07,918 INFO status has been updated to running\n",
      "2025-01-20 21:37:26,987 INFO Daily reduction: mean {'time_shift': {'hours': 0}, 'remove_partial_periods': True}\n",
      "2025-01-20 21:37:26,988 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d752aa8b0944d989bd17de55f4468a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fc1a5d5559812b2c0135f9be525d07a6.nc:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cdsapi\n",
    "from calendar import monthrange\n",
    "\n",
    "#-------- Input --------\n",
    "dataset_name = 'derived-era5-single-levels-daily-statistics'\n",
    "output_filename = 'cloudIce_MOCCHA.nc'\n",
    "STARTYEAR=2018\n",
    "ENDYEAR=2018\n",
    "STARTMONTH=8\n",
    "ENDMONTH=9\n",
    "MAXLAT=90.0\n",
    "MINLON=-180.0\n",
    "MINLAT=65\n",
    "MAXLON=180.0\n",
    "datadir = './prepared-data/anderson_test/ERA5/'\n",
    "\n",
    "#-------- Download ERA5 data from CDS --------\n",
    "for iyear in range(STARTYEAR,ENDYEAR+1):\n",
    "  era5year = str(iyear)\n",
    "  for imonth in range(STARTMONTH,ENDMONTH+1):\n",
    "    era5month = str(imonth).zfill(2)\n",
    "    ndays_in_month = monthrange(int(era5year),imonth)[1]\n",
    "    for iday in range(1,ndays_in_month+1):\n",
    "      era5day = str(iday).zfill(2)\n",
    "      era5filename = era5year+era5month+era5day+'.nc'\n",
    "      if (not os.path.isfile(output_filename)):\n",
    "        c = cdsapi.Client()\n",
    "        c.retrieve(\n",
    "            dataset_name,\n",
    "            {\n",
    "                'product_type': 'reanalysis',\n",
    "                'variable': [\n",
    "                    \"total_column_cloud_ice_water\"\n",
    "                ],\n",
    "                'year': era5year,\n",
    "                'month': era5month,\n",
    "                'day': era5day,\n",
    "                'time': [\n",
    "                    '00:00', '06:00', '12:00',\n",
    "                    '18:00',\n",
    "                ],\n",
    "                'area': [\n",
    "                    MAXLAT, MINLON, MINLAT,\n",
    "                    MAXLON,\n",
    "                ],\n",
    "                'format': 'netcdf',\n",
    "                \"daily_statistic\": \"daily_mean\",\n",
    "                \"time_zone\": \"utc+00:00\",\n",
    "                \"frequency\": \"6_hourly\",\n",
    "            },\n",
    "            output_filename)\n",
    "  os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e3eb5-dc5b-4e0d-b362-a82599056654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"10m_u_component_of_wind\",\n",
    "                    \"10m_v_component_of_wind\",\n",
    "                    \"2m_temperature\",\n",
    "                    \"sea_surface_temperature\",\n",
    "                    \"surface_pressure\",\n",
    "                    \"total_precipitation\",\n",
    "                    \"surface_solar_radiation_downwards\",\n",
    "                    \"surface_thermal_radiation_downwards\",\n",
    "                    \"cloud_base_height\",\n",
    "                    \"high_cloud_cover\",\n",
    "                    \"low_cloud_cover\",\n",
    "                    \"medium_cloud_cover\",\n",
    "                    \"total_column_cloud_ice_water\",\n",
    "                    \"total_column_cloud_liquid_water\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
